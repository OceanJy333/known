import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
  baseURL: process.env.OPENAI_BASE_URL
})

// æµå¼å“åº”ç¼–ç å™¨
class StreamEncoder {
  static encode(type: string, data: any): string {
    return `data: ${JSON.stringify({ type, data, timestamp: new Date().toISOString() })}\n\n`
  }

  static error(message: string): string {
    return `data: ${JSON.stringify({ type: 'error', message, timestamp: new Date().toISOString() })}\n\n`
  }

  static complete(): string {
    return `data: ${JSON.stringify({ type: 'complete', timestamp: new Date().toISOString() })}\n\n`
  }
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { 
      question, 
      knowledgeBase = [], 
      contextCards = [], 
      nodeId,
      conversationHistory = [],
      nodeType = 'ai-chat'
    } = body

    console.log('ğŸš€ [è¾“å‡ºèŠ‚ç‚¹API] æ”¶åˆ°è¯·æ±‚:', {
      question: question?.slice(0, 100) + '...',
      knowledgeBaseSize: knowledgeBase.length,
      contextCardsSize: contextCards.length,
      nodeId,
      nodeType,
      hasHistory: conversationHistory.length > 0,
      // æ·»åŠ æ›´è¯¦ç»†çš„çŸ¥è¯†åº“ä¿¡æ¯
      knowledgeBaseSample: knowledgeBase.slice(0, 3).map((note: any) => ({
        id: note.id,
        title: note.title,
        summary: note.summary?.slice(0, 50) + '...'
      }))
    })

    // åˆ›å»ºæµå¼å“åº”
    const encoder = new TextEncoder()
    const stream = new ReadableStream({
      async start(controller) {
        try {
          // å‘é€å¼€å§‹äº‹ä»¶
          controller.enqueue(encoder.encode(StreamEncoder.encode('start', { nodeId, question })))

          let recalledCards: any[] = []

          // ç¬¬ä¸€é˜¶æ®µï¼šå¬å›ç›¸å…³å¡ç‰‡ï¼ˆå¦‚æœæ²¡æœ‰æä¾›ä¸Šä¸‹æ–‡å¡ç‰‡ï¼‰
          if (contextCards.length === 0 && knowledgeBase.length > 0) {
            console.log('ğŸ“‹ [ç¬¬ä¸€é˜¶æ®µ] å¼€å§‹å¬å›ç›¸å…³å¡ç‰‡')
            controller.enqueue(encoder.encode(StreamEncoder.encode('status', { 
              status: 'recalling', 
              message: 'æ­£åœ¨å¬å›ç›¸å…³å†…å®¹...' 
            })))

            recalledCards = await recallRelevantCards(question, knowledgeBase, controller, encoder)
            
            console.log('âœ… [ç¬¬ä¸€é˜¶æ®µ] å¬å›å®Œæˆ:', {
              recalledCount: recalledCards.length,
              recalledIds: recalledCards.map(c => c.id)
            })
          } else {
            // ä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡å¡ç‰‡
            recalledCards = contextCards
            console.log('ğŸ“ [è·³è¿‡å¬å›] ä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡å¡ç‰‡:', contextCards.length)
          }

          // ç¬¬äºŒé˜¶æ®µï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”
          console.log('ğŸ¤– [ç¬¬äºŒé˜¶æ®µ] å¼€å§‹ç”Ÿæˆå›ç­”')
          controller.enqueue(encoder.encode(StreamEncoder.encode('status', { 
            status: 'generating', 
            message: 'æ­£åœ¨ç”Ÿæˆå›ç­”...' 
          })))

          await generateAnswerWithContext(
            question, 
            recalledCards, 
            conversationHistory, 
            nodeType,
            controller, 
            encoder
          )

          // å‘é€å®Œæˆäº‹ä»¶
          controller.enqueue(encoder.encode(StreamEncoder.encode('complete', { 
            nodeId, 
            recalledCards: recalledCards.map(card => card.id),
            contextUsed: recalledCards.length 
          })))
          controller.enqueue(encoder.encode(StreamEncoder.complete()))

        } catch (error) {
          console.error('âŒ [è¾“å‡ºèŠ‚ç‚¹API] å¤„ç†å¤±è´¥:', error)
          controller.enqueue(encoder.encode(StreamEncoder.error(
            error instanceof Error ? error.message : 'å¤„ç†è¯·æ±‚æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯'
          )))
        } finally {
          controller.close()
        }
      }
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/plain; charset=utf-8',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })

  } catch (error) {
    console.error('âŒ [è¾“å‡ºèŠ‚ç‚¹API] åˆå§‹åŒ–å¤±è´¥:', error)
    return NextResponse.json(
      { error: 'è¯·æ±‚å¤„ç†å¤±è´¥' },
      { status: 500 }
    )
  }
}

// ç¬¬ä¸€é˜¶æ®µï¼šå¬å›ç›¸å…³å¡ç‰‡
async function recallRelevantCards(
  question: string, 
  knowledgeBase: any[], 
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder
): Promise<any[]> {
  
  // ä¼˜åŒ–çŸ¥è¯†åº“æ•°æ®ï¼Œé¿å…tokenè¶…é™
  const optimizedKnowledgeBase = knowledgeBase
    .slice(0, 50) // é™åˆ¶æ•°é‡
    .map(note => ({
      id: note.id,
      title: note.title,
      summary: (note.summary || '').slice(0, 200),
      tags: note.tags,
      category: note.category
    }))

  const matchingPrompt = `ä½œä¸ºçŸ¥è¯†æ£€ç´¢ä¸“å®¶ï¼Œè¯·ä»ç”¨æˆ·çš„ç¬”è®°åº“ä¸­æ‰¾å‡ºä¸é—®é¢˜æœ€ç›¸å…³çš„ç¬”è®°ã€‚

ç”¨æˆ·é—®é¢˜ï¼š${question}

ç¬”è®°åº“ï¼š
${JSON.stringify(optimizedKnowledgeBase, null, 2)}

è¯·åˆ†ææ¯ä¸ªç¬”è®°ä¸é—®é¢˜çš„ç›¸å…³åº¦ï¼Œè¿”å›æœ€ç›¸å…³çš„5ä¸ªç¬”è®°IDåŠå…¶ç›¸å…³åº¦è¯„åˆ†ï¼ˆ0-1ï¼‰ã€‚

è¿”å›æ ¼å¼ï¼ˆå¿…é¡»æ˜¯æœ‰æ•ˆçš„JSONï¼‰ï¼š
{
  "matches": [
    {"id": "note-id", "relevance": 0.95, "reason": "ç›¸å…³åŸå› "}
  ]
}`

  try {
    const matchingResponse = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: matchingPrompt }],
      temperature: 0.1,
      max_tokens: 1000
    })

    const matchingResult = matchingResponse.choices[0]?.message?.content
    if (!matchingResult) {
      throw new Error('AIåŒ¹é…è¿”å›ä¸ºç©º')
    }

    // è§£æåŒ¹é…ç»“æœ
    let matchingData
    try {
      matchingData = JSON.parse(matchingResult)
    } catch (e) {
      console.warn('âš ï¸ [å¬å›] JSONè§£æå¤±è´¥ï¼Œå°è¯•æå–:', matchingResult)
      // å°è¯•æå–JSONéƒ¨åˆ†
      const jsonMatch = matchingResult.match(/\{[\s\S]*\}/)
      if (jsonMatch) {
        matchingData = JSON.parse(jsonMatch[0])
      } else {
        throw new Error('æ— æ³•è§£æAIè¿”å›çš„åŒ¹é…ç»“æœ')
      }
    }

    // å‘é€å¬å›çš„å¡ç‰‡
    const recalledCards = matchingData.matches
      ?.filter((match: any) => match.relevance > 0.6) // åªä¿ç•™ç›¸å…³åº¦é«˜çš„
      ?.map((match: any) => {
        const originalNote = knowledgeBase.find(note => note.id === match.id)
        return originalNote ? { ...originalNote, relevance: match.relevance, reason: match.reason } : null
      })
      ?.filter(Boolean) || []

    // å‘é€å¬å›ç»“æœ
    console.log('ğŸ“¤ [å¬å›] å‘é€å¬å›ç»“æœåˆ°å‰ç«¯:', {
      recalledCardsCount: recalledCards.length,
      recalledCardsSample: recalledCards.slice(0, 3).map((card: any) => ({
        id: card.id,
        title: card.title,
        relevance: card.relevance
      })),
      searchStats: {
        totalNotesSearched: knowledgeBase.length,
        notesFound: recalledCards.length,
        averageRelevance: recalledCards.length > 0 
          ? (recalledCards.reduce((sum: number, card: any) => sum + card.relevance, 0) / recalledCards.length).toFixed(2)
          : '0'
      }
    })
    
    // æ‰“å°åˆ°åç«¯ç»ˆç«¯çš„å…³é”®ä¿¡æ¯
    console.log('\nğŸ”¥ [åç«¯ç»ˆç«¯] å¬å›å¡ç‰‡å‘é€ç¡®è®¤:')
    console.log('   - å¡ç‰‡æ•°é‡:', recalledCards.length)
    console.log('   - å¡ç‰‡IDåˆ—è¡¨:', recalledCards.map((c: any) => c.id))
    console.log('   - å¡ç‰‡æ ‡é¢˜:', recalledCards.map((c: any) => c.title))
    console.log('   - å³å°†å‘é€çš„äº‹ä»¶ç±»å‹: recalled_cards')
    console.log('   - æµå¼ä¼ è¾“çŠ¶æ€: æ­£åœ¨å‘é€...\n')
    
    controller.enqueue(encoder.encode(StreamEncoder.encode('recalled_cards', {
      cards: recalledCards,
      searchStats: {
        totalNotesSearched: knowledgeBase.length,
        notesFound: recalledCards.length,
        averageRelevance: recalledCards.length > 0 
          ? (recalledCards.reduce((sum: number, card: any) => sum + card.relevance, 0) / recalledCards.length).toFixed(2)
          : '0'
      }
    })))

    return recalledCards

  } catch (error) {
    console.error('âŒ [å¬å›] æ™ºèƒ½åŒ¹é…å¤±è´¥:', error)
    
    // å›é€€åˆ°å…³é”®è¯åŒ¹é…
    console.log('ğŸ”„ [å¬å›] å›é€€åˆ°å…³é”®è¯åŒ¹é…')
    const fallbackCards = knowledgeBase
      .filter(note => {
        const content = `${note.title} ${note.summary || ''} ${note.tags?.join(' ') || ''}`.toLowerCase()
        const questionWords = question.toLowerCase().split(' ')
        return questionWords.some(word => word.length > 2 && content.includes(word))
      })
      .slice(0, 3)
      .map(note => ({ ...note, relevance: 0.7, reason: 'å…³é”®è¯åŒ¹é…' }))

    controller.enqueue(encoder.encode(StreamEncoder.encode('recalled_cards', {
      cards: fallbackCards,
      searchStats: {
        totalNotesSearched: knowledgeBase.length,
        notesFound: fallbackCards.length,
        averageRelevance: '0.70'
      },
      fallback: true
    })))

    return fallbackCards
  }
}

// ç¬¬äºŒé˜¶æ®µï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå›ç­”
async function generateAnswerWithContext(
  question: string,
  contextCards: any[],
  conversationHistory: any[],
  nodeType: string,
  controller: ReadableStreamDefaultController,
  encoder: TextEncoder
) {
  
  // æ„å»ºä¸Šä¸‹æ–‡
  const contextContent = contextCards.map(card => `
æ ‡é¢˜ï¼š${card.title}
æ‘˜è¦ï¼š${card.summary || 'æš‚æ— æ‘˜è¦'}
å†…å®¹ï¼š${card.content ? card.content.slice(0, 500) + '...' : 'æš‚æ— è¯¦ç»†å†…å®¹'}
æ ‡ç­¾ï¼š${card.tags?.join(', ') || 'æ— '}
`).join('\n---\n')

  // æ„å»ºå¯¹è¯å†å²
  const historyContent = conversationHistory
    .slice(-4) // åªä¿ç•™æœ€è¿‘4è½®å¯¹è¯
    .map((msg: any) => `${msg.role === 'user' ? 'ç”¨æˆ·' : 'AI'}ï¼š${msg.content}`)
    .join('\n')

  // æ ¹æ®èŠ‚ç‚¹ç±»å‹é€‰æ‹©ç³»ç»Ÿæç¤º
  const systemPrompts = {
    'ai-chat': `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„çŸ¥è¯†åŠ©æ‰‹ã€‚åŸºäºç”¨æˆ·æä¾›çš„çŸ¥è¯†å¡ç‰‡å†…å®¹å’Œå¯¹è¯å†å²ï¼Œä¸ºç”¨æˆ·çš„é—®é¢˜æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„å›ç­”ã€‚

å›ç­”è¦æ±‚ï¼š
1. å……åˆ†åˆ©ç”¨æä¾›çš„çŸ¥è¯†å¡ç‰‡å†…å®¹
2. è€ƒè™‘å¯¹è¯å†å²çš„ä¸Šä¸‹æ–‡
3. ä¿æŒå®¢è§‚ã€å‡†ç¡®çš„è¯­è°ƒ
4. æä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®
5. å¦‚æœçŸ¥è¯†å¡ç‰‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜å¹¶æä¾›é€šç”¨å»ºè®®
6. é€‚å½“å¼•ç”¨çŸ¥è¯†å¡ç‰‡ä¸­çš„å…³é”®ä¿¡æ¯`,
    
    'html-page': 'åŸºäºçŸ¥è¯†å¡ç‰‡å†…å®¹ç”Ÿæˆå®Œæ•´çš„HTMLç½‘é¡µ...',
    'xiaohongshu': 'åŸºäºçŸ¥è¯†å¡ç‰‡å†…å®¹ç”Ÿæˆå°çº¢ä¹¦é£æ ¼çš„å›¾æ–‡å†…å®¹...'
  }

  const systemPrompt = systemPrompts[nodeType as keyof typeof systemPrompts] || systemPrompts['ai-chat']

  const answerPrompt = `
${contextCards.length > 0 ? `å¯ç”¨çŸ¥è¯†å¡ç‰‡ï¼š\n${contextContent}\n` : ''}

${conversationHistory.length > 0 ? `å¯¹è¯å†å²ï¼š\n${historyContent}\n` : ''}

ç”¨æˆ·é—®é¢˜ï¼š${question}

è¯·åŸºäºä¸Šè¿°ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚`

  try {
    const answerResponse = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: answerPrompt }
      ],
      stream: true,
      temperature: 0.7,
      max_tokens: 2000
    })

    // æµå¼å‘é€å›ç­”å†…å®¹
    let fullAnswer = ''
    for await (const chunk of answerResponse) {
      const content = chunk.choices[0]?.delta?.content
      if (content) {
        fullAnswer += content
        controller.enqueue(encoder.encode(StreamEncoder.encode('answer_content', { content })))
      }
    }

    console.log('âœ… [ç”Ÿæˆå›ç­”] å®Œæˆ:', {
      answerLength: fullAnswer.length,
      contextCardsUsed: contextCards.length
    })

  } catch (error) {
    console.error('âŒ [ç”Ÿæˆå›ç­”] å¤±è´¥:', error)
    throw error
  }
}